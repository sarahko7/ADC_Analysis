---
title: "ADC_Code"
author: "Sarah Ko"
date: "April 7, 2019"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set up your system

```{r}

# load packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(FSA)

# set working directory
setwd("~/Duke/Year 2/Spring 2019/Data Analytics/ADC_Analysis/Code")

#check wd
getwd()

# create ggplot theme
SKotheme <- theme_gray(base_size = 15) +
  theme(axis.text = element_text(color = "black"), 
        legend.position = "right", 
        plot.title = element_text(hjust = 0.5))

# set ggplot theme
theme_set(SKotheme)

```

## Import & Explore

```{r}

# import dataset
ADC_raw <- read.csv("../Raw_Data/CalRecycle_ADC_raw.csv")

# explore dataset
view(ADC_raw)
class(ADC_raw)
colnames(ADC_raw)
dim(ADC_raw)

# per the CalRecycle website, segregation into ADC types started in 1998
# therefore, for the analysis, remove data from before 1998
class(ADC_raw$Report.Year)
ADC_data <- filter(ADC_raw, Report.Year >= 1998)
dim(ADC_data)

# explore new dataset
head(ADC_data)
tail(ADC_data)

# tidy the data by gathering the type columns
ADC_gathered <- gather(ADC_data, "Type", "Quantity", Ash:Sludge) %>%
  select(-Total) # remove Total column

# save the tidy dataset
write.csv(ADC_data, row.names = FALSE, file = "../Processed_Data/CalRecycle_ADC_tidy_processed.csv")

# generate summary data
ADC_summary_by_type <- ADC_gathered %>%
  group_by(Type) %>% # group the data by lakename
  filter(!is.na(Quantity)) %>% #remove the records when there are nas Quantity
  summarise(MeanQuarterlyQuantity = mean(Quantity), 
            MinQuarterlyQuantity = min(Quantity), 
            MaxQuarterlyQuantity = max(Quantity), 
            sdQuarterlyQuantity = sd(Quantity), 
            medianQuarterlyQuantity = median(Quantity))

ADC_summary_by_year <- ADC_gathered %>%
  group_by(Report.Year) %>% # group the data by year
  filter(!is.na(Quantity)) %>% #remove the records when there are nas Quantity
  summarise(MeanQuarterlyQuantity = mean(Quantity), 
            MinQuarterlyQuantity = min(Quantity), 
            MaxQuarterlyQuantity = max(Quantity), 
            sdQuarterlyQuantity = sd(Quantity), 
            medianQuarterlyQuantity = median(Quantity))

```

## Create Graphs

```{r}

#SKO: update columns names!!

# Graph 1: for 2017 data, display total by type
total_bytype_2017 <- ADC_gathered %>%
  filter(Report.Year == 2017) %>%
  group_by(Type) %>%
  summarize(Quantity = sum(Quantity))

# convert column Type into factor
class(total_bytype_2017$Type)
total_bytype_2017$Type <- as.factor(total_bytype_2017$Type)

# plot as a bar chart
total_bytype_2017_plot <- 
    ggplot(data=total_bytype_2017, aes(x=Type, y=Quantity)) +
    geom_bar(stat="identity") + 
    xlab("Type") +
    ylab("Quantity (US Tons)") +
    ggtitle("2017 Quantities of ADC by Type") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(total_bytype_2017_plot)

# Graph 2: faceted by Type, display spread of quarterly values by year
quarterlyvalues_byyear_plot <- ggplot(ADC_gathered) +
  geom_boxplot(aes(x = Report.Year, y = Quantity, group = Report.Year)) + 
  facet_wrap(vars(Type), nrow = 5) + 
  xlab("Year") +
  ylab("Quantity (US Tons)") +
  ggtitle("Seasonal Quantities of ADC, Grouped by Year")
print(quarterlyvalues_byyear_plot)

# Graph 3: display data by quarter, all Types on same plot
quarterlyvalues_alltypes_plot <- 
  ggplot(ADC_gathered) + 
  geom_point(aes(x = Report.Quarter, y = Quantity, shape = as.factor(Type), color = as.factor(Report.Year)))
print(quarterlyvalues_alltypes_plot)
##SKO group values under legend

```

## Test 1: Statistical Modeling & Data Visualization

Is there a significant difference in total ADC between report quarters? (e.g. 1, 2, 3, 4)

```{r}

# create dataset with only total values, from 1995-2017
ADC_total_only <- ADC_raw %>%
  select(Report.Year, Report.Quarter, Total) # keep all columns except ADC Types

# convert column Report.Quarter into factor
class(ADC_total_only$Report.Quarter)
ADC_total_only$Report.Quarter <- as.factor(ADC_total_only$Report.Quarter) 

# save the dataset
#write.csv(ADC_total_only, row.names = FALSE, file = "../Processed_Data/CalRecycle_ADC_totalsonly_processed.csv")

# perform one-way ANOVA

# assumption #0: observations are independent (cannot be tested, but assumed to be independent)

# test assumption #1: normality

# null hypothesis is that the dataset is normally distributed
shapiro.test(ADC_total_only$Total[ADC_total_only$Report.Quarter == 1]) # p-value = 0.03312
shapiro.test(ADC_total_only$Total[ADC_total_only$Report.Quarter == 2]) # p-value = 0.02271
shapiro.test(ADC_total_only$Total[ADC_total_only$Report.Quarter == 3]) # p-value = 0.00993
shapiro.test(ADC_total_only$Total[ADC_total_only$Report.Quarter == 4]) # p-value = 0.001305

ggplot(ADC_total_only) +
  geom_freqpoly(aes(x = Total, color = Report.Quarter))

qqnorm(ADC_total_only$Total); qqline(ADC_total_only$Total) # does not match 1:1 ratio

# test assumption #2: equal variances among groups

# null hypothesis is that the variance is the same for the treatment groups
bartlett.test(ADC_total_only$Total ~ ADC_total_only$Report.Quarter) #p-value = 0.9308 # df = 3 (statistical power is very low)

# Try to fix departure from normality with ln of Total. Result is not improved, so keep non-transformed data
ADC_LogTotal <- mutate(ADC_total_only, LogTotal = log(Total))
qqnorm(ADC_LogTotal$LogTotal); qqline(ADC_LogTotal$LogTotal)
bartlett.test(ADC_LogTotal$LogTotal ~ ADC_LogTotal$Report.Quarter)

# Try to fix departure from normality with 1/Total. Result is not improved, so keep non-transformed data
ADC_InvTotal <- mutate(ADC_total_only, InvTotal = 1/Total)
qqnorm(ADC_InvTotal$InvTotal); qqline(ADC_InvTotal$InvTotal)
bartlett.test(ADC_InvTotal$InvTotal ~ ADC_InvTotal$Report.Quarter)

# dataset is not normal, but does fulfill requirement for same variances. proceed with one-way ANOVA
#SKO: sample size is 22 for each group. used parametric (instead of non-parametric bc https://blog.minitab.com/blog/adventures-in-statistics-2/choosing-between-a-nonparametric-test-and-a-parametric-test)

# Format as an aov
ADC_quarter_anova <- aov(ADC_total_only$Total ~ ADC_total_only$Report.Quarter)
ADC_quarter_anova
summary(ADC_quarter_anova)

# Run a post-hoc test for pairwise differences
TukeyHSD(ADC_quarter_anova) # none of the p values are < 0.05
plot(TukeyHSD(ADC_quarter_anova)) # all of the bars overlap
# none of the pairings have significantly different means

# plot the results
ADC_quarter_anova_plot <- ggplot(ADC_total_only, aes(x = Report.Quarter, y = Total)) +
  geom_violin(draw_quantiles = 0.5)
print(ADC_quarter_anova_plot)
##SKO make it pretty

# try non-parametric w/ post hoc, bc sample size is on the smaller end for parametric. non-parametric does not show very different results. df is still low
ADC_quarter_kw <- kruskal.test(ADC_total_only$Total ~ ADC_total_only$Report.Quarter)
ADC_quarter_kw
dunnTest(ADC_total_only$Total, ADC_total_only$Report.Quarter)

```

## Test 2: Statistical Modeling & Data Visualization

Can total annual ADC be represented with a linear model?

```{r}

# create dates corresponding to year & quarter combination
# Q1: Mar 31
# Q2: Jun 30
# Q3: Sep 30
# Q4: Dec 31

# create dataframe of month-date
quarters_to_dates <- data.frame("Quarter" = as.factor(1:4), "Month.Date" = c('3-31', '6-30', '9-30', '12-31'))

# create new dataframe with dates
ADC_fulldate <- ADC_total_only %>% 
  inner_join(quarters_to_dates, by = c("Report.Quarter" =  "Quarter")) %>%
  unite('Quarter.End.Date', c(Report.Year, Month.Date), sep = "-", remove = FALSE)

ADC_fulldate$Quarter.End.Date <- as.Date(ADC_fulldate$Quarter.End.Date, "%Y-%m-%d")
class(ADC_fulldate$Quarter.End.Date)



```

